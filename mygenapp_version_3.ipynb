{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install Libraries Needed\n",
        "\n"
      ],
      "metadata": {
        "id": "YCmwu2h2_1o8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nu7vFhQ19P6w"
      },
      "outputs": [],
      "source": [
        "!pip install -q streamlit opencv-python-headless openai ffmpeg-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch diffusers transformers accelerate"
      ],
      "metadata": {
        "id": "VOBGLXLv9au4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount GDRIVE"
      ],
      "metadata": {
        "id": "v5RHxmQO_9wE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkUMKeAb_058",
        "outputId": "36fa212e-95bb-4bf2-c03e-c616144e715b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MyGenAI App"
      ],
      "metadata": {
        "id": "XipfQQQdLKr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Streamlit app\n",
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "import torch\n",
        "from diffusers import DiffusionPipeline, DPMSolverMultistepScheduler\n",
        "from diffusers.utils import export_to_video\n",
        "import cv2\n",
        "import subprocess\n",
        "from google.colab import files\n",
        "import shutil\n",
        "import openai\n",
        "import os\n",
        "import requests\n",
        "import numpy as np\n",
        "import io\n",
        "import ffmpeg\n",
        "import subprocess\n",
        "\n",
        "\n",
        "# Variables\n",
        "file_name = '' #string file_name refers to the .mp4 created by the model.\n",
        "\n",
        "drive_file_path = '' #string drive_file_path refers to wthe exact path it is saved in Google Drive.\n",
        "\n",
        "drive_path = '' #string drive_path refers to the drive location excluding file_name.\n",
        "\n",
        "tmp_file_path = '' #string refering to tmp_file_path location where colab saves the video from model\n",
        "\n",
        "def save_to_drive(tmp_file_path, drive_path):\n",
        "  return shutil.copy(tmp_file_path, drive_path)\n",
        "\n",
        "def display_video(video):\n",
        "  # TESTING Define the drive file path to your video\n",
        "  # drive_video_path = '/content/drive/My Drive/MyFolder/tmpg4m7wi_9.mp4'  # Update with your actual file path\n",
        "  # Display the video in Streamlit\n",
        "  st.video(video)\n",
        "\n",
        "def convert_video(video_path):\n",
        "  # Input video file path\n",
        "  input_file = video_path\n",
        "\n",
        "  # maniputlate paths\n",
        "  old_file_name = video_path.split('/')[2]\n",
        "  new_file_name = \"NEW\" + old_file_name\n",
        "\n",
        "  # Output video file path\n",
        "  output_file = '/tmp/' + new_file_name\n",
        "  ffmpeg.input(input_file).output(output_file, vcodec='libx264').run()\n",
        "  return output_file\n",
        "\n",
        "st.title(\"ZeroScope Video Generation üé•\")\n",
        "\n",
        "##################### Video is Created From Model üé•üé•üé• ##########################################################################################\n",
        "# Create a Streamlit text input widget for entering the prompt\n",
        "prompt = st.text_input(\"Enter a prompt:\", \"Darth Vader surfing on waves\")\n",
        "\n",
        "# Create a button to trigger video generation\n",
        "if st.button(\"Generate Video\"):\n",
        "    with st.spinner(\"Generating video...\"):\n",
        "        # Load the pre-trained model and configure the pipeline\n",
        "        pipe = DiffusionPipeline.from_pretrained(\"cerspense/zeroscope_v2_576w\", torch_dtype=torch.float16)\n",
        "        pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "        pipe.enable_model_cpu_offload()\n",
        "\n",
        "        # Generate video frames\n",
        "        video_frames = pipe(prompt, num_inference_steps=40, height=320, width=576, num_frames=40).frames\n",
        "        video_path = export_to_video(video_frames)\n",
        "        tmp_file_path = convert_video(video_path)\n",
        "\n",
        "######################## Video is Displayed üñºÔ∏èüñºÔ∏èüñºÔ∏è ########################################################################################\n",
        "    ### Show results\n",
        "    display_video(tmp_file_path)\n",
        "\n",
        "###################### Video is saved to Google Drive üëáüëáüëá ##########################################################################################\n",
        "    if st.button(\"Save to Google Drive\"):\n",
        "    ### Colab üëâüëâüëâ Drive ###\n",
        "      with st.spinner(\"Saving video to Drive...\"):\n",
        "        # Define the path where you want to save the video in Google Drive\n",
        "        drive_path = '/content/drive/My Drive/MyFolder/'\n",
        "        drive_file_path = save_to_drive(tmp_file_path, drive_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUoLh1kf-MWT",
        "outputId": "d4653379-2070-457d-8aaf-dd9ee02ea4d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run in Streamlit\n",
        "\n",
        "1.   Open Tunnel\n",
        "2.   Get Tunnel URL\n",
        "3.   Run app.py in Streamlit\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TJjrNOVEL05d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\n",
        "!chmod +x cloudflared-linux-amd64\n",
        "# import subprocess\n",
        "# subprocess.Popen([\"./cloudflared-linux-amd64\", \"tunnel\", \"--url\", \"http://localhost:8501\"])\n",
        "!nohup /content/cloudflared-linux-amd64 tunnel --url http://localhost:8501 &"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTce5hUV-MaE",
        "outputId": "0665f4c1-3a25-45d4-9716-d840d83bb87e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-24 20:41:36--  https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/cloudflare/cloudflared/releases/download/2023.8.2/cloudflared-linux-amd64 [following]\n",
            "--2023-10-24 20:41:36--  https://github.com/cloudflare/cloudflared/releases/download/2023.8.2/cloudflared-linux-amd64\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/106867604/e6bb31a7-5cfa-446c-bf2a-c8eccfa0256e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231024%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231024T204119Z&X-Amz-Expires=300&X-Amz-Signature=b8229cd16b6cb725a36c1c4cbf2397aa605532d72aefe02e1dd09112413c1e80&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=106867604&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-10-24 20:41:36--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/106867604/e6bb31a7-5cfa-446c-bf2a-c8eccfa0256e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231024%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231024T204119Z&X-Amz-Expires=300&X-Amz-Signature=b8229cd16b6cb725a36c1c4cbf2397aa605532d72aefe02e1dd09112413c1e80&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=106867604&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 36461990 (35M) [application/octet-stream]\n",
            "Saving to: ‚Äòcloudflared-linux-amd64‚Äô\n",
            "\n",
            "cloudflared-linux-a 100%[===================>]  34.77M   204MB/s    in 0.2s    \n",
            "\n",
            "2023-10-24 20:41:36 (204 MB/s) - ‚Äòcloudflared-linux-amd64‚Äô saved [36461990/36461990]\n",
            "\n",
            "nohup: appending output to 'nohup.out'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!grep -o 'https://.*\\.trycloudflare.com' nohup.out | head -n 1 | xargs -I {} echo \"Your tunnel url {}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTVTdjp--MdD",
        "outputId": "a5b5667a-bb8d-4b43-9c86-9bf2082c5b66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your tunnel url https://ks-builders-fitted-ranges.trycloudflare.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run /content/app.py &>/content/logs.txt &"
      ],
      "metadata": {
        "id": "zfSij9uz-MfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LDj6R2w4-Mh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7aU1-voY-MkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZLcVn80U-Mnv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}